{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Iteration. Notes for the Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same algorithms to be used:LR, DT, RF and SVM.\n",
    "\n",
    "Another set of features to use. Pre-processed files \"FeatureSelectionDTOutput.csv\" and \"FeatureSelectionDTTestOutput.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97044, 11)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data.\n",
    "import pandas as pd\n",
    "data_train = pd.read_csv(\"FeatureSelectionDTOutput.csv\")\n",
    "\n",
    "# split values into inpits and outputs.\n",
    "values_train = data_train.values\n",
    "X_train = values_train[:,0:10]\n",
    "y_train = values_train[:,10]\n",
    "\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40158, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data.\n",
    "data_test_full = pd.read_csv(\"FeatureSelectionDTTestOutput.csv\")\n",
    "\n",
    "# Create new dataset with features previously selected.\n",
    "columns_needed = list(data_train.columns)\n",
    "data_test = data_test_full[columns_needed].copy()\n",
    "\n",
    "# split values into inpits and outputs.\n",
    "values_test = data_test.values\n",
    "X_test = values_test[:,0:10]\n",
    "y_test = values_test[:,10]\n",
    "\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the LR model with defualt hyperparameters.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fit the model using default hyperparameters.\n",
    "# K, you don't split into train and validate sets??\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run predictions on TEST set and see the accuracy.\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr_predicted = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, lr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create array of values for tuned hyperparameters.\n",
    "lr_params = {'dual' : [True,False], \n",
    "             'C' : [0.1, 0.5, 1.0, 1.5, 2.0, 2.5], \n",
    "             'max_iter' : [100, 150, 200, 300, 500, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run random search and initiate the model with tuned parameters.\n",
    "lr_random = RandomizedSearchCV(estimator=lr, param_distributions=lr_params, cv = 3, n_jobs=-1, random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "lr_random_result = lr_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (lr_random_result.best_score_, lr_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "lr_random = lr_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "lr_random.fit(X_train, y_train)\n",
    "lr_random.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr_random_predicted = lr_random.predict(X_test)\n",
    "print(confusion_matrix(y_test, lr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"LR default hyperparameters test accuracy: \", lr.score(X_test,y_test),', parameters: ', '\\n', lr.get_params(),'\\n')\n",
    "print(\"LR tuned hyperparameters test accuracy: \", lr_random.score(X_test,y_test),', parameters: ', '\\n', lr_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a DT model using default hyperparameters.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model on train data.\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check model accuracy on the TEST set.\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of values for tuned hyperparameters.\n",
    "dt_params = {'max_depth': [None, 0.1, 1, 3, 5, 10], \n",
    "             'min_samples_leaf': [0.04, 0.06, 0.08, 1], \n",
    "             'max_features': [None, 0.2, 0.4,0.6, 0.8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run random search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "dt_random = RandomizedSearchCV(estimator=dt, param_distributions=dt_params, cv = 10, n_jobs=-1, random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "dt_random_result = dt_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (dt_random_result.best_score_, dt_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "dt_random = dt_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "dt_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "dt_random.fit(X_train, y_train)\n",
    "dt_random.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, dt_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DT default hyperparameters test accuracy: \", dt.score(X_test,y_test),', parameters: ', '\\n', dt.get_params(),'\\n')\n",
    "print(\"DT tuned hyperparameters test accuracy: \", dt_random.score(X_test,y_test),', parameters: ', '\\n', dt_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a RF model using default hyperparameters.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model on train data.\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model accuracy on the TEST set.\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters.\n",
    "rf_params = { 'n_estimators': [1, 5, 10, 30, 50, 100, 300, 400, 500], \n",
    "             'max_depth': [None, 4, 6, 8], \n",
    "             'min_samples_leaf': [0.1, 0.2, 0.5, 1], \n",
    "             'max_features': ['auto', 'log2', 'sqrt']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run random search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_params, cv = 3, n_jobs=-1, random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "rf_random_result = rf_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (rf_random_result.best_score_, rf_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "rf_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"RF default hyperparameters test accuracy: \", rf.score(X_test,y_test),', parameters: ', '\\n', rf.get_params(),'\\n')\n",
    "print(\"RF tuned hyperparameters test accuracy: \", rf_random.score(X_test,y_test),', parameters: ', '\\n', rf_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svclassifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, svclassifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SVC hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters.\n",
    "svc_params = { 'C': [0.1, 0.5, 1, 3, 5], \n",
    "             'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "             'degree': [2, 3, 4], \n",
    "              'gamma': [0.01, 0.1, 1, 10]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run random search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "svc_random = RandomizedSearchCV(estimator=svclassifier, n_iter=3, param_distributions=svc_params, cv = 3, n_jobs=-1, \n",
    "                                random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "svc_random_result = svc_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (svc_random_result.best_score_, svc_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "svc_random = svc_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "svc_random.fit(X_train, y_train)\n",
    "svc_random.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, svc_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SVC default hyperparameters test accuracy: \", svclassifier.score(X_test,y_test), \n",
    "      ', parameters: ', '\\n', svclassifier.get_params(),'\\n')\n",
    "print(\"SVC tuned hyperparameters test accuracy: \", svc_random.score(X_test,y_test), \n",
    "      ', parameters: ', '\\n', svc_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Algorithms Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LR tuned hyperparameters test accuracy: \", lr_random.score(X_test,y_test))\n",
    "print(\"DT tuned hyperparameters test accuracy: \", dt_random.score(X_test,y_test))\n",
    "print(\"RF tuned hyperparameters test accuracy: \", rf_random.score(X_test,y_test))\n",
    "print(\"SVC tuned hyperparameters test accuracy: \", svc_random.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
