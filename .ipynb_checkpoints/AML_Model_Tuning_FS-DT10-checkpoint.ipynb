{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes for the Project Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same algorithms to be used: LR, DT, RF and SVM.\n",
    "\n",
    "Another set of features to use. Pre-processed files \"FS_DT10_train_output.csv\" and \"FS_DT10_test_output.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING TRAIN AND TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data.\n",
    "import pandas as pd\n",
    "data_train = pd.read_csv(\"FS_DT10_train_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split values into inpits and outputs.\n",
    "values_train = data_train.values\n",
    "X_train = values_train[:,0:10]\n",
    "y_train = values_train[:,10]\n",
    "\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40158, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data.\n",
    "data_test_full = pd.read_csv(\"FeatureSelectionDTTestOutput.csv\")\n",
    "\n",
    "# Create new dataset with features previously selected.\n",
    "columns_needed = list(data_train.columns)\n",
    "data_test = data_test_full[columns_needed].copy()\n",
    "\n",
    "# split values into inpits and outputs.\n",
    "values_test = data_test.values\n",
    "X_test = values_test[:,0:10]\n",
    "y_test = values_test[:,10]\n",
    "\n",
    "data_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the LR model with defualt hyperparameters.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using default hyperparameters.\n",
    "# K, you don't split into train and validate sets??\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415060510981622"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run predictions on TEST set and see the accuracy.\n",
    "lr.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17732  2347]\n",
      " [    2 20077]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr_predicted = lr.predict(X_test)\n",
    "print(confusion_matrix(y_test, lr_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create array of values for tuned hyperparameters.\n",
    "lr_params = {'dual' : [True,False], \n",
    "             'C' : [0.1, 0.5, 1.0, 1.5, 2.0, 2.5], \n",
    "             'max_iter' : [100, 150, 200, 300, 500, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.896583 using {'max_iter': 500, 'dual': True, 'C': 0.1}\n",
      "Execution time: 47.78657102584839\n"
     ]
    }
   ],
   "source": [
    "# Run random search and initiate the model with tuned parameters.\n",
    "lr_random = RandomizedSearchCV(estimator=lr, param_distributions=lr_params, cv = 3, n_jobs=-1, random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "lr_random_result = lr_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (lr_random_result.best_score_, lr_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "lr_random = lr_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9458638378405299"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "lr_random.fit(X_train, y_train)\n",
    "lr_random.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17910  2169]\n",
      " [    5 20074]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "lr_random_predicted = lr_random.predict(X_test)\n",
    "print(confusion_matrix(y_test, lr_random_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR default hyperparameters test accuracy:  0.9415060510981622 , parameters:  \n",
      " {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'warn', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "LR tuned hyperparameters test accuracy:  0.9458638378405299 , parameters:  \n",
      " {'C': 0.1, 'class_weight': None, 'dual': True, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'warn', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'warn', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"LR default hyperparameters test accuracy: \", lr.score(X_test,y_test),', parameters: ', '\\n', lr.get_params(),'\\n')\n",
    "print(\"LR tuned hyperparameters test accuracy: \", lr_random.score(X_test,y_test),', parameters: ', '\\n', lr_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a DT model using default hyperparameters.\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on train data.\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5261218188156781"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model accuracy on the TEST set.\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19677   402]\n",
      " [18628  1451]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, dt.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array of values for tuned hyperparameters.\n",
    "dt_params = {'max_depth': [None, 0.1, 1, 3, 5, 10], \n",
    "             'min_samples_leaf': [0.04, 0.06, 0.08, 1], \n",
    "             'max_features': [None, 0.2, 0.4,0.6, 0.8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.919665 using {'min_samples_leaf': 0.06, 'max_features': 0.2, 'max_depth': 5}\n",
      "Execution time: 8.52574896812439\n"
     ]
    }
   ],
   "source": [
    "# Run random search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "dt_random = RandomizedSearchCV(estimator=dt, param_distributions=dt_params, cv = 10, n_jobs=-1, random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "dt_random_result = dt_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (dt_random_result.best_score_, dt_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "dt_random = dt_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=5,\n",
       "                       max_features=0.2, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=0.06, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "dt_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "dt_random.fit(X_train, y_train)\n",
    "dt_random.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20079     0]\n",
      " [20079     0]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, dt_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT default hyperparameters test accuracy:  0.5261218188156781 , parameters:  \n",
      " {'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'} \n",
      "\n",
      "DT tuned hyperparameters test accuracy:  0.5 , parameters:  \n",
      " {'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': 0.2, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 0.06, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': False, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(\"DT default hyperparameters test accuracy: \", dt.score(X_test,y_test),', parameters: ', '\\n', dt.get_params(),'\\n')\n",
    "print(\"DT tuned hyperparameters test accuracy: \", dt_random.score(X_test,y_test),', parameters: ', '\\n', dt_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a RF model using default hyperparameters.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model on train data.\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000498032770556"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check model accuracy on the TEST set.\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20064    15]\n",
      " [20062    17]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters.\n",
    "rf_params = { 'n_estimators': [1, 5, 10, 30, 50, 100, 300, 400, 500], \n",
    "             'max_depth': [None, 4, 6, 8], \n",
    "             'min_samples_leaf': [0.1, 0.2, 0.5, 1], \n",
    "             'max_features': ['auto', 'log2', 'sqrt']\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.920964 using {'n_estimators': 500, 'min_samples_leaf': 0.1, 'max_features': 'sqrt', 'max_depth': 4}\n",
      "Execution time: 110.90869903564453\n"
     ]
    }
   ],
   "source": [
    "# Run random search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=rf_params, cv = 3, n_jobs=-1, random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "rf_random_result = rf_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (rf_random_result.best_score_, rf_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "rf_random = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=4, max_features='sqrt', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=0.1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF default hyperparameters test accuracy:  0.5000498032770556 , parameters:  \n",
      " {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 10, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False} \n",
      "\n",
      "RF tuned hyperparameters test accuracy:  0.7592758603516111 , parameters:  \n",
      " {'bootstrap': True, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 0.1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 500, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"RF default hyperparameters test accuracy: \", rf.score(X_test,y_test),', parameters: ', '\\n', rf.get_params(),'\\n')\n",
    "print(\"RF tuned hyperparameters test accuracy: \", rf_random.score(X_test,y_test),', parameters: ', '\\n', rf_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svclassifier = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\K\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8830619054733801"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15574  4505]\n",
      " [  191 19888]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, svclassifier.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## SVC hyperparameters tuning (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a grid of hyperparameters.\n",
    "svc_params = { 'C': [0.1, 0.5, 1, 3, 5], \n",
    "             'kernel': ['linear', 'poly', 'rbf'], # removed 'sigmoid'\n",
    "             'degree': [2, 3, 4], \n",
    "              'gamma': [0.01, 0.1, 1, 10]\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.947416 using {'kernel': 'poly', 'gamma': 10, 'degree': 2, 'C': 0.1}\n",
      "Execution time: 2412.093564748764\n"
     ]
    }
   ],
   "source": [
    "# Run random search.\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "svc_random = RandomizedSearchCV(estimator=svclassifier, n_iter=3, param_distributions=svc_params, cv = 3, n_jobs=-1, \n",
    "                                random_state = 2019)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "svc_random_result = svc_random.fit(X_train, y_train)\n",
    "finish_time = time.time()\n",
    "\n",
    "# Summarize results\n",
    "print(\"Best: %f using %s\" % (svc_random_result.best_score_, svc_random_result.best_params_))\n",
    "print(\"Execution time: \" + str((finish_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best values of hyperparameters to the model.\n",
    "svc_random = svc_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9236515762737189"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the tuned model on TRAIN set and check the accuracy\n",
    "svc_random.fit(X_train, y_train)\n",
    "svc_random.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18485  1594]\n",
      " [ 1472 18607]]\n"
     ]
    }
   ],
   "source": [
    "# Build confusion matrix.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, svc_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVC tuning Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC default hyperparameters test accuracy:  0.8830619054733801 , parameters:  \n",
      " {'C': 1.0, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'auto_deprecated', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False} \n",
      "\n",
      "SVC tuned hyperparameters test accuracy:  0.9236515762737189 , parameters:  \n",
      " {'C': 0.1, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 2, 'gamma': 10, 'kernel': 'poly', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"SVC default hyperparameters test accuracy: \", svclassifier.score(X_test,y_test), \n",
    "      ', parameters: ', '\\n', svclassifier.get_params(),'\\n')\n",
    "print(\"SVC tuned hyperparameters test accuracy: \", svc_random.score(X_test,y_test), \n",
    "      ', parameters: ', '\\n', svc_random.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Algorithms Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR tuned hyperparameters test accuracy:  0.9458638378405299\n",
      "[[17910  2169]\n",
      " [    5 20074]]\n",
      "\n",
      "DT tuned hyperparameters test accuracy:  0.5\n",
      "[[20079     0]\n",
      " [20079     0]]\n",
      "\n",
      "RF tuned hyperparameters test accuracy:  0.7592758603516111\n",
      "[[20051    28]\n",
      " [ 9639 10440]]\n",
      "\n",
      "SVC tuned hyperparameters test accuracy:  0.9236515762737189\n",
      "[[18485  1594]\n",
      " [ 1472 18607]]\n"
     ]
    }
   ],
   "source": [
    "print(\"LR tuned hyperparameters test accuracy: \", lr_random.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, lr_random_predicted))\n",
    "print()\n",
    "\n",
    "print(\"DT tuned hyperparameters test accuracy: \", dt_random.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, dt_random.predict(X_test)))\n",
    "print()\n",
    "\n",
    "print(\"RF tuned hyperparameters test accuracy: \", rf_random.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, rf_random.predict(X_test)))\n",
    "print()\n",
    "\n",
    "print(\"SVC tuned hyperparameters test accuracy: \", svc_random.score(X_test,y_test))\n",
    "print(confusion_matrix(y_test, svc_random.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
